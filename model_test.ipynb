{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476729e-a3cc-4eb9-b01c-2a0ad43c8435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d33ccb-0975-4d2d-9ef2-d553172f6e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.rnn.LSTM'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\kospeech\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LAS(\n",
       "  (listener): Listener(\n",
       "    (pLSTM_layer0): pBLSTMLayer(\n",
       "      (BLSTM): LSTM(80, 512, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    )\n",
       "    (pLSTM_layer1): pBLSTMLayer(\n",
       "      (BLSTM): LSTM(2048, 512, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    )\n",
       "    (pLSTM_layer2): pBLSTMLayer(\n",
       "      (BLSTM): LSTM(2048, 512, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (speller): Speller(\n",
       "    (rnn_layer): LSTM(2524, 1024, num_layers=2, batch_first=True)\n",
       "    (attention): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "      (phi): Linear(in_features=1024, out_features=64, bias=True)\n",
       "      (psi): Linear(in_features=1024, out_features=64, bias=True)\n",
       "    )\n",
       "    (character_distribution): Linear(in_features=2048, out_features=1500, bias=True)\n",
       "    (softmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from model.las_model import Listener, Speller, LAS\n",
    "\n",
    "PATH = 'C:/Users/USER/Desktop/jiwon/las-pytorch/runs/kospeech_dropout0.3_retry-BEST_LOSS-epoch16.pth.tar'\n",
    "checkpoint = torch.load(PATH)\n",
    "print(checkpoint['etype'])\n",
    "listener = Listener(input_feature_dim= checkpoint['einput'],\n",
    "        hidden_size=checkpoint['ehidden'],\n",
    "        num_layers=checkpoint['elayer'],\n",
    "        dropout=checkpoint['edropout'],\n",
    "        bidirectional=True,\n",
    "        rnn_unit=\"LSTM\",\n",
    "        use_gpu=True)\n",
    "\n",
    "speller = Speller(hidden_size= checkpoint['dhidden'],\n",
    "        num_layers= checkpoint['dlayer'],\n",
    "        bidirectional= True,\n",
    "        rnn_unit= \"LSTM\",\n",
    "        vocab_size= checkpoint['dvocab_size'],                       # 61 phonemes + 2 for <sos> & <eos>\n",
    "        multi_head= 1,                          # Number of heads for multi-head attention\n",
    "        decode_mode= 1,                         # Decoding mode, 0 : feed char distribution to next timestep, 1: feed argmax, 2: feed sampled vector\n",
    "        use_mlp_in_attention= True,                  # Set to False to exclude phi and psi in attention formula\n",
    "        mlp_dim_in_attention= 64,                   #\n",
    "        mlp_activate_in_attention= 'relu',        #\n",
    "        listener_hidden_size= 512,\n",
    "        max_label_len= 576)\n",
    "        \n",
    "\n",
    "las_model = LAS(listener, speller)\n",
    "las_model.cuda()\n",
    "optimizer = torch.optim.Adam(params=las_model.parameters(), lr=0.002)\n",
    "\n",
    "\n",
    "las_model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optim_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "\n",
    "las_model.eval()\n",
    "#model.eval()\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c8e741c-b803-4ecc-9078-59d2ceebacc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['dvocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb6a6e8-204b-43c5-8728-ee9e006d3223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx,input,label\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a234ecda-fa68-454a-aa9c-a1954bd444d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2088/2932788420.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "test_loader.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a68097-f942-4fc3-8c54-63b2c21a2960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : [array(['이', '', '대', '리', '', '아', '니', '야', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>'], dtype='<U5'), array(['안', '녕', '하', '세', '요', '', '일', '찍', '', '출', '근', '하', '시', '네',\n",
      "       '요'], dtype='<U1')]\n",
      "true : [array(['이', '', '대', '리', '', '아', '니', '야', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>'], dtype='<U5'), array(['안', '녕', '하', '세', '요', '', '일', '찍', '', '출', '근', '하', '시', '네',\n",
      "       '요'], dtype='<U1')]\n",
      "pred : [array(['만', '', '원', '지', '하', '철', '에', '', '타', '면', '', '한', '', '',\n",
      "       '', '', '', '비', '비', '해', '서', '', '일', '', '', '못', '', '하', '겠',\n",
      "       '더'], dtype='<U1'), array(['나', '도', '요', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>'], dtype='<U5')]\n",
      "true : [array(['만', '원', '', '지', '하', '철', '을', '', '타', '면', '', '하', '루', '',\n",
      "       '종', '일', '', '피', '곤', '해', '서', '', '일', '을', '', '못', '하', '겠',\n",
      "       '더', '라'], dtype='<U1'), array(['저', '도', '요', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>'], dtype='<U5')]\n",
      "pred : [array(['그', '래', '서', '', '친', '한', '번', '', '거', '기', '다', '가', '', '사',\n",
      "       '실', '', '분', '위', '기', '를', '', '집', '', '', '', '', '', '', '',\n",
      "       '어'], dtype='<U1'), array(['아', '침', '밥', '은', '', '회', '사', '', '앞', '', '편', '의', '점', '에',\n",
      "       '서', '', '해', '결', '해', '도', '', '되', '니', '까', '요', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>'], dtype='<U5')]\n",
      "true : [array(['그', '래', '서', '', '아', '침', '밥', '은', '', '포', '기', '하', '고', '',\n",
      "       '삼', '십', '', '분', '', '일', '찍', '', '출', '근', '하', '기', '로', '',\n",
      "       '했', '어'], dtype='<U1'), array(['아', '침', '밥', '은', '', '회', '사', '', '앞', '', '편', '의', '점', '에',\n",
      "       '서', '', '해', '결', '해', '도', '', '되', '니', '까', '요', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>'], dtype='<U5')]\n",
      "pred : [array(['코', '로', '나', '', '때', '문', '에', '', '얼', '굴', '이', '', '줄', '어',\n",
      "       '서', '', '힘', '이', '겠'], dtype='<U1'), array(['저', '만', '', '그', '런', '가', '요', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>'], dtype='<U5')]\n",
      "true : [array(['코', '로', '나', '', '때', '문', '에', '', '월', '급', '이', '', '줄', '어',\n",
      "       '서', '', '힘', '들', '지'], dtype='<U1'), array(['저', '만', '', '그', '런', '가', '요', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>'], dtype='<U5')]\n",
      "pred : [array(['다', '들', '', '맞', '찬', '가', '', '되', '죠', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>'], dtype='<U5'), array(['어', '떻', '게', '', '지', '출', '은', '', '줄', '이', '고', '', '있', '어'],\n",
      "      dtype='<U1')]\n",
      "true : [array(['다', '들', '', '마', '찬', '가', '지', '죠', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>'], dtype='<U5'), array(['어', '떻', '게', '', '지', '출', '은', '', '줄', '이', '고', '', '있', '어'],\n",
      "      dtype='<U1')]\n",
      "pred : [array(['애', '들', '', '학', '원', '비', '를', '', '좀', '', '줄', '이', '자', '고',\n",
      "       '', '했', '더', '니', '', '아', '내', '가', '', '', '한', '', '', '', '',\n",
      "       '더'], dtype='<U1'), array(['그', '렇', '다', '고', '', '부', '모', '님', '', '용', '돈', '을', '', '안',\n",
      "       '', '드', '릴', '', '수', '도', '', '없', '고', '', '고', '민', '이', '에',\n",
      "       '요', '<sos>'], dtype='<U5')]\n",
      "true : [array(['애', '들', '', '학', '원', '비', '를', '', '좀', '', '줄', '이', '자', '고',\n",
      "       '', '했', '더', '니', '', '아', '내', '가', '', '펄', '펄', '', '뛰', '더',\n",
      "       '라', '구'], dtype='<U1'), array(['그', '렇', '다', '고', '', '부', '모', '님', '', '용', '돈', '을', '', '안',\n",
      "       '', '드', '릴', '', '수', '도', '', '없', '고', '', '고', '민', '이', '에',\n",
      "       '요', '<sos>'], dtype='<U5')]\n",
      "pred : [array(['내', '가', '', '뭐', '라', '도', '', '줄', '이', '지', '', '않', '으', '면',\n",
      "       '', '줄', '일', '', '데', '가', '', '없', '지', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>'], dtype='<U5'), array(['집', '체', '기', '라', '는', '', '게', '', '한', '번', '', '늘', '리', '기',\n",
      "       '는', '', '쉬', '워', '도', '', '줄', '이', '기', '는', '', '어', '렵', '거',\n",
      "       '든'], dtype='<U1')]\n",
      "true : [array(['내', '가', '', '뭐', '라', '도', '', '줄', '이', '지', '', '않', '으', '면',\n",
      "       '', '줄', '일', '', '데', '가', '', '없', '지', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>'], dtype='<U5'), array(['지', '출', '이', '라', '는', '', '게', '', '한', '번', '', '늘', '리', '기',\n",
      "       '는', '', '쉬', '워', '도', '', '줄', '이', '기', '는', '', '어', '렵', '거',\n",
      "       '든'], dtype='<U1')]\n",
      "pred : [array(['이', '제', '는', '', '교', '통', '비', '도', '', '아', '까', '워', '요',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>'], dtype='<U5'), array(['한', '', '달', '', '용', '돈', '이', '', '오', '십', '만', '', '원', '인',\n",
      "       '데', '', '교', '통', '비', '로', '만', '', '십', '오', '만', '', '원', '',\n",
      "       '정', '도'], dtype='<U1')]\n",
      "true : [array(['이', '제', '는', '', '교', '통', '비', '도', '', '아', '까', '워', '요',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
      "       '<sos>', '<sos>', '<sos>'], dtype='<U5'), array(['한', '', '달', '', '용', '돈', '이', '', '오', '십', '만', '', '원', '인',\n",
      "       '데', '', '교', '통', '비', '로', '만', '', '십', '오', '만', '', '원', '',\n",
      "       '정', '도'], dtype='<U1')]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from solver.solver import batch_iterator\n",
    "\n",
    "from utils.data import AudioDataLoader, AudioDataset\n",
    "import numpy as np\n",
    "\n",
    "params={\"data\":{\"vocab\":\"C:/Users/USER/Desktop/jiwon/las-pytorch/data/kospeech/processed/idx2chap.csv\",\"batch_size\":8,\"test\":\"C:/Users/USER/Desktop/jiwon/las-pytorch/data/kospeech/processed/test-clean-test.csv\",\"vocab_size\":1500},\"model\":{\"listener\":{\"num_layers\":3}}}\n",
    "test_dataset = AudioDataset(params, \"test\")\n",
    "test_loader = AudioDataLoader(test_dataset, num_workers=1).loader\n",
    "\n",
    "\n",
    "tf_rate = 0.9\n",
    "val_loss = []\n",
    "val_ler = []\n",
    "val_step = 0\n",
    "for i, (data) in tqdm(enumerate(test_loader), total=len(test_loader), leave=False, desc=\"Test\"):\n",
    "    # print(\n",
    "    #     f\"Current Epoch: {epoch} | Epoch step: {epoch_step}/{len(train_loader)} Validating step: {val_step}/{len(dev_loader)}\",\n",
    "    #     end=\"\\r\",\n",
    "    #     flush=True,\n",
    "    # )\n",
    "\n",
    "    inputs = data[1][\"inputs\"].cuda()\n",
    "    labels = data[2][\"targets\"].cuda()\n",
    "\n",
    "    batch_loss, batch_ler = batch_iterator(\n",
    "        batch_data=inputs,\n",
    "        batch_label=labels,\n",
    "        las_model=las_model,\n",
    "        optimizer=optimizer,\n",
    "        tf_rate=tf_rate,\n",
    "        is_training=False,\n",
    "        max_label_len=30,\n",
    "        label_smoothing=0.1,\n",
    "        vocab_dict=test_dataset.char2idx,\n",
    "    )\n",
    "    if i % 100 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "    val_loss.append(batch_loss)\n",
    "    val_ler.extend(batch_ler)\n",
    "    val_step += 1 \n",
    "\n",
    "val_loss = np.array([sum(val_loss) / len(val_loss)])\n",
    "val_ler = np.array([sum(val_ler) / len(val_ler)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93a73714-5f87-4d1e-a97f-348827eff5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/3659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : [2.1720921]\n",
      "test ler : [0.30126758]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from solver.solver import batch_iterator\n",
    "\n",
    "from utils.data import AudioDataLoader, AudioDataset\n",
    "import numpy as np\n",
    "\n",
    "params={\"data\":{\"vocab\":\"C:/Users/USER/Desktop/jiwon/las-pytorch/data/kospeech/processed/idx2chap.csv\",\"batch_size\":8,\"test\":\"C:/Users/USER/Desktop/jiwon/las-pytorch/data/kospeech/processed/test-clean.csv\",\"vocab_size\":1500},\"model\":{\"listener\":{\"num_layers\":3}}}\n",
    "test_dataset = AudioDataset(params, \"test\")\n",
    "test_loader = AudioDataLoader(test_dataset, num_workers=1).loader\n",
    "\n",
    "\n",
    "tf_rate = 0.9\n",
    "#loss = []\n",
    "#ler = []\n",
    "val_loss = []\n",
    "val_ler = []\n",
    "val_step = 0\n",
    "for i, (data) in tqdm(enumerate(test_loader), total=len(test_loader), leave=False, desc=\"Test\"):\n",
    "    # print(\n",
    "    #     f\"Current Epoch: {epoch} | Epoch step: {epoch_step}/{len(train_loader)} Validating step: {val_step}/{len(dev_loader)}\",\n",
    "    #     end=\"\\r\",\n",
    "    #     flush=True,\n",
    "    # )\n",
    "\n",
    "    inputs = data[1][\"inputs\"].cuda()\n",
    "    labels = data[2][\"targets\"].cuda()\n",
    "\n",
    "    batch_loss, batch_ler = batch_iterator(\n",
    "        batch_data=inputs,\n",
    "        batch_label=labels,\n",
    "        las_model=las_model,\n",
    "        optimizer=optimizer,\n",
    "        tf_rate=tf_rate,\n",
    "        is_training=False,\n",
    "        max_label_len=30,\n",
    "        label_smoothing=0.1,\n",
    "        vocab_dict=test_dataset.char2idx,\n",
    "    )\n",
    "    if i % 100 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "    val_loss.append(batch_loss)\n",
    "    val_ler.extend(batch_ler)\n",
    "    val_step += 1 \n",
    "\n",
    "val_loss = np.array([sum(val_loss) / len(val_loss)])\n",
    "val_ler = np.array([sum(val_ler) / len(val_ler)])\n",
    "\n",
    "print(\"test loss :\", val_loss)\n",
    "print(\"test ler :\", val_ler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fa7af-15b4-4149-964d-b4b380353cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06f46126-ab4f-4c72-bfe2-9f8b319c66e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (Temp/ipykernel_34048/704738897.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_34048/704738897.py\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    params={\"\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "batch_data = np.load(path)\n",
    "batch_label = label\n",
    "tf_rate = 0.9\n",
    "is_training = True\n",
    "\n",
    "raw_pred_seq, _ = las_model(\n",
    "        batch_data=batch_data, batch_label=batch_label, teacher_force_rate=tf_rate, is_training=is_training,\n",
    "    )\n",
    "pred_y = (torch.cat([torch.unsqueeze(each_y, 1) for each_y in raw_pred_seq], 1)[:, :max_label_len, :]).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2327ae-1e4b-42ce-8df3-7ea9fef6ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label_smoothing == 0.0 or not (is_training):\n",
    "        pred_y = pred_y.permute(0, 2, 1)  # pred_y.contiguous().view(-1,output_class_dim)\n",
    "        true_y = torch.max(batch_label, dim=2)[1][:, :max_label_len].contiguous()  # .view(-1)\n",
    "\n",
    "        loss = criterion(pred_y, true_y)\n",
    "        # variable -> numpy before sending into LER calculator\n",
    "        batch_ler = LetterErrorRate(\n",
    "            torch.max(pred_y.permute(0, 2, 1), dim=2)[1].cpu().numpy(),  # .reshape(current_batch_size,max_label_len),\n",
    "            true_y.cpu().data.numpy(),\n",
    "        )  # .reshape(current_batch_size,max_label_len), data)\n",
    "\n",
    "    else:\n",
    "        true_y = batch_label[:, :max_label_len, :].contiguous()\n",
    "        true_y = true_y.type(torch.cuda.FloatTensor) if use_gpu else true_y.type(torch.FloatTensor)\n",
    "        loss = label_smoothing_loss(pred_y, true_y, label_smoothing=label_smoothing)\n",
    "        # batch_ler = [1.0]\n",
    "        # print(true_y)\n",
    "        # print(\"vs\")\n",
    "        # print(pred_y)\n",
    "        batch_ler = LetterErrorRate(\n",
    "            torch.max(pred_y, dim=2)[1].cpu().numpy(),  # .reshape(current_batch_size,max_label_len),\n",
    "            torch.max(true_y, dim=2)[1].cpu().data.numpy(),\n",
    "        )  # .reshape(current_batch_size,max_label_len), data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5a151-af6b-4bb3-b4a7-f1e57564c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = loss.cpu().data.numpy()\n",
    "\n",
    "print(batch_loss, batch_ler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
